import { GoogleGenAI, Type } from "@google/genai";
import { DatasetInfo, GeneratedResult } from "../types";

const MASTER_ROADMAP = `
ğŸ—ºï¸ Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ Ø¬Ø§Ù…Ø¹ Û° ØªØ§ Û±Û°Û° Ù¾Ø±ÙˆÚ˜Ù‡â€ŒÙ‡Ø§ÛŒ Data Science / Machine Learning

Ù…Ø±Ø­Ù„Ù‡ 0 â€“ ÙÙ‡Ù… Ù…Ø³Ø¦Ù„Ù‡
Ù†ÙˆØ¹ Ù¾Ø±ÙˆÚ˜Ù‡: Regression / Classification / Clustering / Unsupervised Analysis / Forecasting / Recommendation / Anomaly Detection
Ø³ÙˆØ§Ù„Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ: Ù‡Ø¯Ù Ù†Ù‡Ø§ÛŒÛŒ Ú†ÛŒØ³ØªØŸ (Predict, Classify, Cluster, Analyze, Forecast) Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú†ÛŒØ³ØªØŸ (Numeric, Categorical, Text, Time-Series, Image, Graph) Ù…Ø¹ÛŒØ§Ø± Ù…ÙˆÙÙ‚ÛŒØª Ú†ÛŒØ³ØªØŸ (Accuracy, RÂ², RMSE, F1-score, ROC-AUC, Silhouette, Profit, KPIâ€¦) Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§: latencyØŒ interpretabilityØŒ storageØŒ privacy
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø±Ø²ÙˆÙ…Ù‡â€ŒØ§ÛŒ: Ù†ÙˆØ¹ Ù¾Ø±ÙˆÚ˜Ù‡ Ù…Ø´Ø®Øµ â†’ ØªØ¹ÛŒÛŒÙ† preprocessing Ùˆ pipeline Ø§ÙˆÙ„ÛŒÙ‡ ØªØ¹Ø¯Ø§Ø¯ featureâ€ŒÙ‡Ø§ØŒ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ â†’ Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨

Ù…Ø±Ø­Ù„Ù‡ 1 â€“ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ (Data Collection / Acquisition)
Ù…Ù†Ø§Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡: CSV, Excel, Database, API, Web Scraping, IoT / Sensor, Images, Text, Graph Data
Ø§Ø¯ØºØ§Ù… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: merge, join, concat, append
Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ù…Ù†Ø¨Ø¹ Ùˆ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ: Ú†Ù†Ø¯ dataset Ø¯Ø§Ø±ÛŒÙ…ØŸ â†’ merge / join Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù‚Øµ ÛŒØ§ Ù¾Ø±Ø§Ú©Ù†Ø¯Ù‡ØŸ â†’ cleaning Ù„Ø§Ø²Ù… Ø§Ø³Øª

Ù…Ø±Ø­Ù„Ù‡ 2 â€“ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Exploratory Data Analysis / EDA)
Basic EDA: df.head(), df.info(), df.describe(), df.isna().sum()
Visualization: Histogram, Boxplot, Violin plot, Countplot Scatter plot, Pairplot Heatmap correlation, Cluster map
Feature types: Numeric, Categorical, Ordinal, Binary, Text, Datetime, Image
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ: Ø¨Ø±Ø±Ø³ÛŒ imbalance Ø¯Ø± classification Ø¨Ø±Ø±Ø³ÛŒ skew / outlier Ø¯Ø± numeric features Ù†ÛŒØ§Ø² Ø¨Ù‡ feature engineering Ùˆ transformation

Ù…Ø±Ø­Ù„Ù‡ 3 â€“ ØªÙ…ÛŒØ²Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ (Data Cleaning / Preprocessing)
3.1 Handling Missing Values: Drop row/column Imputation: mean, median, mode, KNN imputer, Iterative imputer, MICE Interpolation (linear, spline) Ø¨Ø±Ø§ÛŒ Ø³Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ù…Ø§Ù†ÛŒ Advanced: predictive imputation (RandomForest, regression)
3.2 Handling Outliers: IQR, Z-score, Modified Z-score LOF, ABOD, Isolation Forest Decision: Ø­Ø°ÙØŒ cap, transformation, robust model
3.3 Categorical Encoding: One-Hot Encoding Label / Ordinal Encoding Target / Mean Encoding Frequency / Count Encoding Embedding (Neural Networks) Hashing Encoding (High-cardinality features)
3.4 Scaling / Normalization: StandardScaler (mean=0, std=1) MinMaxScaler (0-1) RobustScaler (median, IQR) MaxAbsScaler Log / Box-Cox / Yeo-Johnson (skewed data)
3.5 Text & Date Processing: Text: Tokenization, Stemming, Lemmatization, TF-IDF, Word2Vec, BERT embeddings Date/Time: Extract day, month, year, weekday, hour, cyclical features (sin/cos)
3.6 Feature Engineering: Interaction terms: x1*x2, x1/x2 Polynomial features Binning / discretization Aggregation / rolling statistics Domain-specific transformations
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ: Ù…Ø¯Ù„ Ø®Ø·ÛŒ ÛŒØ§ ÙØ§ØµÙ„Ù‡â€ŒØ§ÛŒØŸ â†’ scaling Ùˆ transformation Ù„Ø§Ø²Ù… Tree-basedØŸ â†’ scaling Ú©Ù… Ø§Ù‡Ù…ÛŒØª

Ù…Ø±Ø­Ù„Ù‡ 4 â€“ ØªØ­Ù„ÛŒÙ„ Ø¢Ù…Ø§Ø±ÛŒ Ùˆ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ÙØ±Ø¶ÛŒÙ‡
Normality: Shapiro-Wilk, Dâ€™Agostino, Kolmogorov-Smirnov, Q-Q plot
Two-group comparison: T-test, Mann-Whitney U
Multi-group comparison: ANOVA, Kruskal-Wallis
Categorical dependency: Chi-Square test, Fisher Exact
Correlation: Pearson (linear & normal), Spearman (rank), Kendall Tau
Variance analysis: Levene test, Bartlett test
Feature importance: Mutual information, f_classif, f_regression
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ: Numeric & normal â†’ parametric tests Skewed / ordinal â†’ non-parametric tests

Ù…Ø±Ø­Ù„Ù‡ 5 â€“ Visualization Ù¾ÛŒØ´Ø±ÙØªÙ‡
Pairplots / Scatter matrix
Heatmaps / Cluster maps
PCA / t-SNE / UMAP (dimension reduction & visualization)
Boxplot / Violin plot per group
Feature importance plots
Residual plots (Regression)
Confusion Matrix & ROC curves (Classification)
Silhouette plots (Clustering)
ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ: ØªØ¹Ø¯Ø§Ø¯ feature Ø²ÛŒØ§Ø¯ â†’ PCA / t-SNE visualization Classification â†’ confusion matrix Regression â†’ residual plots

Ù…Ø±Ø­Ù„Ù‡ 6 â€“ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ÛŒÙ†Ú¯
Train/Test Split (stratified for classification)
Cross-validation / K-Fold / Stratified K-Fold / TimeSeriesSplit
Feature selection: Filter methods: correlation threshold, ANOVA F-value, mutual info Wrapper methods: RFE, sequential feature selection Embedded: Lasso, Tree-based feature importance

Ù…Ø±Ø­Ù„Ù‡ 7 â€“ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
Regression: Linear, Ridge, Lasso, ElasticNet Polynomial regression Decision Tree / RandomForest / XGBoost / LightGBM / CatBoost Neural Networks (MLP, CNN for time series)
Classification: Logistic Regression, SVM, KNN Tree-based: Decision Tree, RandomForest, XGBoost, LightGBM, CatBoost Neural Networks: MLP, CNN, RNN, Transformers Probabilistic: Naive Bayes
Clustering / Unsupervised: KMeans, KMedoids, Hierarchical, DBSCAN, HDBSCAN
Dimensionality reduction: PCA, t-SNE, UMAP
Anomaly Detection: LOF, Isolation Forest, One-Class SVM, Autoencoder
Baseline Model: Simple model as reference â†’ mean, median, dummy classifier

Ù…Ø±Ø­Ù„Ù‡ 8 â€“ Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
Train / Fit model
Metrics: Regression: RÂ², MSE, RMSE, MAE, MAPE Classification: Accuracy, Precision, Recall, F1-score, ROC-AUC, LogLoss Clustering: Silhouette, Davies-Bouldin, Calinski-Harabasz Ranking/Recommendation: NDCG, MAP, Precision@k
Cross-validation / Hyperparameter tuning: GridSearchCV, RandomizedSearchCV, Bayesian Optimization
Regularization: L1, L2, ElasticNet
Ensemble methods: Bagging, Boosting, Stacking, Voting

Ù…Ø±Ø­Ù„Ù‡ 9 â€“ ØªØ­Ù„ÛŒÙ„ Ø®Ø·Ø§ Ùˆ residual
Regression: residual plots, heteroscedasticity check
Classification: confusion matrix, misclassified samples
Feature importance / SHAP / LIME / PDP
Learning curves: bias-variance trade-off

Ù…Ø±Ø­Ù„Ù‡ 10 â€“ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯Ù„
Feature engineering / selection
Transformation on features/target
Handling imbalance: SMOTE, undersampling, class weights
Ensemble / Stacking / Bagging / Boosting
Neural network tuning: learning rate, layers, batch size, dropout

Ù…Ø±Ø­Ù„Ù‡ 11 â€“ Ù…Ø³ØªÙ†Ø¯Ø³Ø§Ø²ÛŒ Ùˆ Reporting
ØªÙˆØ¶ÛŒØ­ Ù…Ø±Ø§Ø­Ù„ØŒ ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ØŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ metrics
Interpretation / recommendation
Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ presentation ÛŒØ§ Ø±Ø²ÙˆÙ…Ù‡

Ù…Ø±Ø­Ù„Ù‡ 12 â€“ Deployment / Production
Pipeline: preprocessing + model
Serialization: pickle / joblib / ONNX
API / Web app / Streamlit / FastAPI
Monitoring model drift / retraining strategy
`;

export const analyzeAndGenerate = async (
  dataset: DatasetInfo,
  userPrompt: string
): Promise<GeneratedResult> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const dataContext = `
    Dataset Filename: ${dataset.filename}
    Columns: ${dataset.columns.join(", ")}
    Column Types: ${JSON.stringify(dataset.columnTypes)}
    First 3 rows sample: ${JSON.stringify(dataset.preview.slice(0, 3))}
  `;

  const systemInstruction = `
    You are an expert Senior Data Scientist named "AutoDS". 
    Your goal is to build a HIGHLY CUSTOMIZED execution plan based on the "MASTER_ROADMAP" provided below.
    
    CRITICAL INSTRUCTIONS:
    1.  **Analyze** the user's goal and dataset strictly.
    2.  **Select** relevant steps from the MASTER_ROADMAP. You must NOT just summarize; you must pick specific techniques mentioned (e.g., if it's imbalanced classification, explicitly select SMOTE from Stage 10 and Stratified K-Fold from Stage 6).
    3.  **Map** the roadmap: Your output JSON "roadmap" must follow the logical flow of the MASTER_ROADMAP but only include what is necessary for this specific project.
    4.  **Python Code**: Generate a robust, production-grade Python script (pandas, sklearn, matplotlib, seaborn).
    
    MASTER_ROADMAP:
    ${MASTER_ROADMAP}
  `;

  const prompt = `
    User Project Goal: "${userPrompt}"
    
    Dataset Info:
    ${dataContext}

    Task:
    1. Create a Custom Roadmap JSON: Select specific methods from the Master Roadmap.
    2. Write Python Code: Implement the selected roadmap. Ensure to handle missing values, encoding, and scaling based on the column types provided.
  `;

  const response = await ai.models.generateContent({
    model: "gemini-2.5-flash", 
    config: {
      systemInstruction: systemInstruction,
      responseMimeType: "application/json",
      responseSchema: {
        type: Type.OBJECT,
        properties: {
          analysisSummary: { type: Type.STRING, description: "A comprehensive summary of the strategy in Persian." },
          roadmap: {
            type: Type.ARRAY,
            items: {
              type: Type.OBJECT,
              properties: {
                stage: { type: Type.STRING },
                description: { type: Type.STRING },
                tasks: { type: Type.ARRAY, items: { type: Type.STRING } },
                algorithms: { type: Type.ARRAY, items: { type: Type.STRING } },
                reasoning: { type: Type.STRING }
              }
            }
          },
          pythonCode: { type: Type.STRING, description: "The complete Python code." }
        }
      }
    },
    contents: [{ role: "user", parts: [{ text: prompt }] }]
  });

  const text = response.text;
  if (!text) {
    throw new Error("No response from AI");
  }

  return JSON.parse(text) as GeneratedResult;
};